{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,glob\n",
    "from urllib.parse import quote \n",
    "import requests,json,os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_datafile_path = 'data/'\n",
    "temp_files_path = 'data/temp_files/'\n",
    "main_file_name = f'{main_datafile_path}metro_ridership_by_line_stn_time.csv'\n",
    "xlsx_path = 'data/total_stn_info_20230317.xlsx'\n",
    "temp_info_name = f'{temp_files_path}temp_info.csv'\n",
    "key_path = 'data/key/kakaoapikey.txt'\n",
    "heatmap_data = f'{main_datafile_path}merged_lines.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stn_name_modification(name=main_file_name):\n",
    "    if name == main_file_name:\n",
    "        df_st = pd.read_csv(name,encoding='euc-kr')\n",
    "        df_st['지하철역'] = df_st['지하철역'].str.replace('(', ' ',regex=False,).str.split().str[0]\n",
    "        for i in df_st.index:\n",
    "            if df_st.loc[i, '지하철역'][-1] == '역':\n",
    "                df_st.loc[i, '지하철역'] = df_st.loc[i, '지하철역'][:-1]\n",
    "        return df_st\n",
    "    else:\n",
    "        df_st = pd.read_csv(name,encoding='euc-kr')\n",
    "        df_st.drop(columns=['등록일자'],inplace=True)\n",
    "        df_st.rename(columns={'역명': '지하철역'},inplace=True)\n",
    "        df_st['지하철역'] = df_st['지하철역'].str.replace('(', ' ',regex=False,).str.split().str[0]\n",
    "        for i in df_st.index:\n",
    "            if df_st.loc[i, '지하철역'][-1] == '역':\n",
    "                df_st.loc[i, '지하철역'] = df_st.loc[i, '지하철역'][:-1]\n",
    "        return df_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_sep_preproc_main():\n",
    "    \n",
    "    df = stn_name_modification()\n",
    "    lines = df.호선명.unique().tolist()\n",
    "    df_dict = {line: df[df['호선명'] == line].copy() for line in lines}\n",
    "    for line, frame in df_dict.items():\n",
    "        # frame = df[df['호선명']==line].copy()\n",
    "        frame['새벽 승차인원'] = frame.loc[:,['04시-05시 승차인원','05시-06시 승차인원']].sum(axis=1)\n",
    "        frame['새벽 하차인원'] = frame.loc[:,['04시-05시 하차인원','05시-06시 하차인원']].sum(axis=1)\n",
    "\n",
    "        frame['출근시간 승차인원'] = frame.loc[:,['06시-07시 승차인원','07시-08시 승차인원','08시-09시 승차인원']].sum(axis=1)\n",
    "        frame['09-16시 승차인원'] = frame.loc[:,['09시-10시 승차인원','10시-11시 승차인원','11시-12시 승차인원',\n",
    "                                                '12시-13시 승차인원','13시-14시 승차인원','14시-15시 승차인원','16시-17시 승차인원']].sum(axis=1)\n",
    "        frame['퇴근시간 승차인원'] = frame.loc[:,['17시-18시 승차인원','18시-19시 승차인원','19시-20시 승차인원']].sum(axis=1)\n",
    "        frame['야간 승차인원'] = frame.loc[:,['20시-21시 승차인원','21시-22시 승차인원','22시-23시 승차인원',\n",
    "                                            '23시-24시 승차인원','00시-01시 승차인원','01시-02시 승차인원']].sum(axis=1)\n",
    "        frame['출근시간 하차인원'] = frame.loc[:,['06시-07시 하차인원','07시-08시 하차인원','08시-09시 하차인원']].sum(axis=1)\n",
    "        frame['퇴근시간 하차인원'] = frame.loc[:,['17시-18시 하차인원','18시-19시 하차인원','19시-20시 하차인원']].sum(axis=1)\n",
    "        frame['09-16시 하차인원'] = frame.loc[:,['09시-10시 하차인원','10시-11시 하차인원','11시-12시 하차인원',\n",
    "                                                '12시-13시 하차인원','13시-14시 하차인원','14시-15시 하차인원','16시-17시 하차인원']].sum(axis=1)\n",
    "        frame['야간 하차인원'] = frame.loc[:,['20시-21시 하차인원','21시-22시 하차인원','22시-23시 하차인원',\n",
    "                                            '23시-24시 하차인원','00시-01시 하차인원','01시-02시 하차인원']].sum(axis=1)\n",
    "        frame['총 승차인원'] = frame.loc[:,['새벽 승차인원','출근시간 승차인원','09-16시 승차인원','야간 승차인원']].sum(axis=1)\n",
    "        frame['총 하차인원'] = frame.loc[:,['새벽 하차인원','출근시간 하차인원','09-16시 하차인원','야간 하차인원']].sum(axis=1)\n",
    "        frame = frame[['사용월', '호선명', '지하철역', '출근시간 승차인원', '출근시간 하차인원', \n",
    "                        '09-16시 승차인원', '09-16시 하차인원', '퇴근시간 승차인원', '퇴근시간 하차인원',\n",
    "                        '새벽 승차인원','새벽 하차인원','야간 승차인원', '야간 하차인원','총 승차인원','총 하차인원']]\n",
    "        \n",
    "        frame.loc[(frame['호선명'] == '2호선') & (frame['지하철역'] == '신천'), '지하철역'] = '잠실새내'\n",
    "\n",
    "        frame.to_csv(f'{temp_files_path}{line}.csv',index=False,encoding='utf-8')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtn_line_info(year):\n",
    "    path = temp_files_path\n",
    "    line_info = [\n",
    "        ([f'{path}1호선.csv', f'{path}경부선.csv', f'{path}경원선.csv', f'{path}경인선.csv', f'{path}장항선.csv'], '1호선'),\n",
    "        ([f'{path}2호선.csv'], '2호선'),\n",
    "        ([f'{path}3호선.csv', f'{path}일산선.csv'], '3호선'),\n",
    "        ([f'{path}4호선.csv', f'{path}과천선.csv', f'{path}안산선.csv'], '4호선'),\n",
    "        ([f'{path}5호선.csv'], '5호선'),\n",
    "        ([f'{path}6호선.csv'], '6호선'),\n",
    "        ([f'{path}7호선.csv'], '7호선'),\n",
    "        ([f'{path}8호선.csv'], '8호선'),\n",
    "        ([f'{path}수인선.csv', f'{path}분당선.csv'], '수인분당선'),\n",
    "        ([f'{path}경의선.csv', f'{path}중앙선.csv'], '경의중앙선'),\n",
    "        ([f'{path}공항철도 1호선.csv'], '공항철도')\n",
    "    ]\n",
    "    if year >= 2019:\n",
    "        line_info.append(([f'{path}9호선.csv', f'{path}9호선2~3단계.csv'], '9호선'))\n",
    "    else:\n",
    "        line_info.append(([f'{path}9호선.csv', f'{path}9호선2단계.csv', f'{path}9호선2~3단계.csv'], '9호선'))\n",
    "    return line_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_temp_files():\n",
    "    temp_path = os.path.join('data', 'temp_files', '*.csv')\n",
    "    for file in glob.glob(temp_path):\n",
    "        os.remove(file)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_lines(year=2019):\n",
    "    line_list = []\n",
    "    line_info = rtn_line_info(year)\n",
    "    for df_list, line_name in line_info:\n",
    "        df_copies = []\n",
    "        for file in df_list:\n",
    "            df = pd.read_csv(file)\n",
    "            df_copies.append(df.copy())\n",
    "        result = pd.concat(df_copies, axis=0)\n",
    "        result = result.reset_index(drop=True)\n",
    "        result.호선명 = line_name\n",
    "        cols = list(result.columns)[:3]\n",
    "        target = list(result.columns)[3:]\n",
    "        res = result.groupby(cols)[target].agg('sum').reset_index()\n",
    "        line_list.append(res)\n",
    "    final = pd.concat(line_list,axis=0)\n",
    "    rm_temp_files()\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_main():\n",
    "    line_sep_preproc_main()\n",
    "    final = preprocessing_lines()\n",
    "    final.to_csv(f'{main_datafile_path}merged_lines.csv',index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stn_sub_modification(year,ck_week):\n",
    "    name = f'{main_datafile_path}{year}.csv'\n",
    "    \n",
    "    df1 = stn_name_modification(name)\n",
    "    cols = list(df1.columns)[:3]\n",
    "    target = list(df1.columns)[3:]\n",
    "    df1['사용일자'] = pd.to_datetime(df1['사용일자'], format='%Y%m%d')\n",
    "    # 평일과 주말 구분하는 새로운 열 생성\n",
    "    df1['주중/주말'] = df1['사용일자'].apply(lambda x: '주말' if x.weekday() >= 5 else '주중')\n",
    "    # 주중/주말 선택    나중에 에러방지 추가해야함\n",
    "    rtn_week = '주중' if ck_week == '주중' else '주말'\n",
    "    weekday_df = df1[df1['주중/주말'] == rtn_week]\n",
    "    week_df = weekday_df.copy()\n",
    "    week_df['사용일자'] = pd.to_datetime(weekday_df['사용일자']).dt.strftime('%Y%m%d').astype(int)\n",
    "    df_list = []\n",
    "    for i in range(1, 13):\n",
    "        start_date = year*10000 + i*100\n",
    "        end_date = start_date + 100\n",
    "        df_temp = week_df[(week_df['사용일자'] >= start_date) & (week_df['사용일자'] < end_date)].copy()\n",
    "        df_temp['사용일자'] = year*100 + i\n",
    "        df_temp = df_temp.groupby(cols)[target].agg('sum').reset_index()\n",
    "        df_list.append(df_temp)\n",
    "    df_res = pd.concat(df_list, axis=0)\n",
    "    df_res.to_csv(f'{main_datafile_path}{year}_{ck_week}_sub_info.csv', index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_sub(year,ck_week):\n",
    "    \n",
    "    stn_sub_modification(year,ck_week)\n",
    "    df = pd.read_csv(f'{main_datafile_path}{year}_{ck_week}_sub_info.csv')\n",
    "    df = df.rename(columns={'역명': '지하철역', '노선명':'호선명', '사용일자':'사용월'})\n",
    "    \n",
    "    lines = df.호선명.unique().tolist()\n",
    "    df_dict = {line: df[df['호선명'] == line].copy() for line in lines}\n",
    "    for line, frame in df_dict.items():\n",
    "        frame.loc[(frame['호선명'] == '2호선') & (frame['지하철역'] == '신천'), '지하철역'] = '잠실새내'\n",
    "        frame.to_csv(f'{temp_files_path}{line}.csv',index=False,encoding='utf-8')\n",
    "\n",
    "    final = preprocessing_lines(year)\n",
    "    rm_temp_files()\n",
    "    final.to_csv(f'{main_datafile_path}{year}_{ck_week}_merged_lines.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kakao_location(place):\n",
    "    with open({key_path}) as f_:\n",
    "        kakao_key = f_.read()\n",
    "    base_url = \"https://dapi.kakao.com/v2/local/search/address.json\"\n",
    "    url = f'{base_url}?query={quote(place)}'\n",
    "    header = {'Authorization':f'KakaoAK {kakao_key}'}\n",
    "    result = requests.get(url, headers=header).json()\n",
    "    lat_ = float(result['documents'][0]['y'])\n",
    "    lng_ = float(result['documents'][0]['x'])\n",
    "    return lat_,lng_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rtn_addr(df,target):\n",
    "    str_addr = df[df.지하철역 == target].도로명주소.values[-1]\n",
    "    return str_addr.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stn_lat_lng():\n",
    "    df = pd.read_excel(xlsx_path,engine='openpyxl')\n",
    "    df.to_csv(temp_info_name,index=False)\n",
    "    df = pd.read_csv(temp_info_name)\n",
    "    df = df[['역사명','역사도로명주소','운영기관명']]\n",
    "    df.rename(columns={'역사명':'지하철역','역사도로명주소':'도로명주소'},inplace=True)\n",
    "    exclude_list = ['대전교통공사', '대구도시철도공사', '부산광역시 부산교통공사', '부산-김해경전철㈜','광주광역시 도시철도공사']\n",
    "    for exclude in exclude_list:\n",
    "        df = df[df['운영기관명'] != exclude]\n",
    "    df.drop(columns=['운영기관명'],inplace=True)\n",
    "    df['지하철역'] = df['지하철역'].str.replace('(', ' ',regex=False,).str.split().str[0]\n",
    "    for i in df.index:\n",
    "        if df['지하철역'][i][-1] == '역':\n",
    "            df['지하철역'][i] = df['지하철역'][i][:-1]\n",
    "    df.drop_duplicates(subset=['지하철역'],keep='first',inplace=True)\n",
    "    df = df[~df['도로명주소'].str.contains('부산|울산')]\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    temp1 =[]\n",
    "    for i in df.index:\n",
    "        try:\n",
    "            target = df['지하철역'][i].strip()\n",
    "            temp1.append(kakao_location(rtn_addr(df,target)))\n",
    "        except:\n",
    "            print(i, df.지하철역[i])\n",
    "            \n",
    "    df_test = pd.DataFrame(temp1,columns=('lat','lng'))\n",
    "    df2 = pd.concat([df, df_test], axis=1)\n",
    "    df2.to_csv(f'{main_datafile_path}stn_r_addr_final.csv',index=False)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lat_lng(name=heatmap_data):\n",
    "    df_latlng = pd.read_csv(f'{main_datafile_path}stn_r_addr_final.csv')\n",
    "    df_latlng.drop(columns=['도로명주소'], inplace=True)\n",
    "\n",
    "    df_main = pd.read_csv(name)\n",
    "    res = pd.merge(df_main, df_latlng, on='지하철역', how='left')\n",
    "    res.to_csv(f'{main_datafile_path}lines_4heatmap_{name[5:9]}.csv', index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일일 데이터는 2020.csv 형식으로 'euc-kr' 인코딩 파일\n",
    "# 메인 파일 전처리\n",
    "# preproc_main()\n",
    "# 일일 데이터 전처리 // 'year' , '주중 or 주말'\n",
    "preproc_sub(2020,'주중')\n",
    "# 히트맵 사용하기위한 처리\n",
    "# add_lat_lng()\n",
    "# 일일 데이터 히트맵 처리 // 해당 년도 파일명\n",
    "add_lat_lng('data/2020_주중_merged_lines.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
